\chapter{Aprendizado de máquina}

	% TODO colocar referência ao curso do Andrew Ng
	O termo Aprendizado de Máquina (\emph{Machine Learning}) surgiu em 1959, sendo utilizado pela primeira vez  pelo cientista americano Arthur Samuel. O termo foi por ele definido como "o campo de estudos que dá a um computador a habilidade de aprender sem ser explicitamente programado" (tradução livre dos autores). Em 1998, Tom Mitchel - outro cientista da computação americano - propôs uma explicação menos abstrata do termo da seguinte maneira: "um programa de computador aprende com a experiência E com respeito a uma classe de tarefas T e medida de performance P se sua performace nas tarefas T, sendo medida por P, aumenta com o aumento da experiência E".

	% TODO colocar referencia https://hbr.org/2017/07/whats-driving-the-machine-learning-explosion
	Apesar do conceito de aprendizado de máquina existir desde a década de 50, seu crescimento e relevância aumentaram apenas na última decada. Alguns fatores levaram a esse crescimento acelerado. Os principais foram o aumento da quantidade de dados coletados e disponíveis - e aplicações de \emph{IoT} têm propulsionado esse aumento -, a melhora nos algoritmos, e o \emph{hardware} cada vez mais poderoso dos computadores. Esses últimos dois fatores permitem que a vasta quantidade de dados que possuímos possam ser analisados em tempo viável.

	\section{Aprendizado de máquina no projeto Hedwig}

		No projeto Hedwig, a utilização de aprendizado de máquina tem o intuito de trazer melhorias de usabilidade do sistema ao usuário, além de poder trazer medidas de segurança à casa do mesmo.

		As melhorias de usabilidade podem ocorrer, por exemplo, quando o sistema aprende alguma rotina do usuário e se torna então capaz de prever quando determinada ação seria solicitada pelo usuário. A partir disso, ele então poderia passar a realizar tal ação automaticamente, ou sugerir a realização dela para o usuário, sem que seja necessário que o usuário proativamente aja para solicitar a mesma.

		No quesito de segurança, o sistema pode, a partir do aprendizado de rotinas, detectar ações suspeitas na casa (como por exemplo a abertura da porta de entrada em horário não usual), e opcionalmente agir para intervir quando tal tipo de ação é detectada.

		No Hedwig, foi desenvolvida uma análise baseada em dados coletados durante os meses de setembro e outubro, em um dos módulos que mantivemos instalados - o módulo de corredor, que já foi citado no capítulo anterior. A análise aqui descrita focou-se em gerar um algoritmo capaz de prever quando o usuário iria solicitar ao sistema a ativação do relé 1, que, no caso do módulo em análise está conectado à lampada do corredor.

		% TODO adicionar aqui caso mais análises tenham sido feitas

	\section{Implementação}
		% TODO possivelmente falar sobre a possiblidade de utilização de sistemas prontos em nuvem para ML
		% (Google Cloud, Tensor Flow, AWS ML, Microsoft (Luis?), IBM (Bluemix?))

		\subsection{Linguagem, ferramentas e bibliotecas}
			% TODO maybe get some references for paragraph below

			Uma das vantagens da popularização que se vê atualmente do uso de aprendizado de máquina é o surgimento de muitas facilidades para o desenvolvimento de aplicações que envolvam esse tema, devido às vantagens que advém de existir grande comunidade trabalhando com isso.

			Atualmente as duas principais linguagens sendo utilizadas para ciência de dados e aprendizado de máquina são Python e R. As duas são linguagens interpretadas, e que possuem funcionalidade REPL (Read-Eval-Print-Loop), possibilitando desenvolvimento altamente interativo e de fácil visualização de dados e gráficos enquanto se programa.

			Para o desenvolvimento de funcionalidades de aprendizado de máquina no Hedwig, foi escolhida a linguagem Python. Apesar de R ser uma linguagem que já nasceu voltada à análise de dados e tratamento estatístico, Python possui diversos pacotes e bibliotecas que conseguem adicionar tais funcionalidades à mesma. Esses pacotes estão altamente popularizados, e portanto é muito fácil percorrer suas documentações e procurar ajuda em fóruns online para acelerar o aprendizado de suas funcionalidades. Python, por sua vez, é uma linguagem de uso geral (\emph{general purpose language}), o que também tem seus lados positivos. Além de ser uma linguagem extremamente bem estabelecida, o fato de ser de uso geral implica que existem também pacotes e bibliotecas que possibilitam o uso de Python para desenvolvimento de aplicativos com funcionalidades de \emph{back-end} para serviços \emph{web}. Isso se torna altamente interessante por nos possibilitar facilmente transformar essa aplicação em um microsserviço, que interaja em tempo real com o servidor em nuvem do Hedwig, permitindo que o serviço de aprendizado de máquina aja em tempo real com toda a aplicação.

			Os principais pacotes sendo utilizados para auxiliar nas funcionalidades de análise de dados e aprendizado de máquina são:

			\begin{description}
				\item [Numpy] Pacote que dá à linguagem Python algumas facilidades para se lidar com estruturas numéricas como matrizes.
				\item [Pandas] Pacote para manuseio de dados. Dá facilidades para a importação de dados de fontes externas, e a utilzação dos mesmos a partir disso.
				\item [Scikit] Pacote com funcionalidades de análise de dados, e implementação dos principais algoritmos de aprendizado de máquina.
				\item [Pylab] Pacote que implementa funcionalidades para geração de gráficos
				% \item [Matplotlib]
				% \item [Seaborn]
			\end{description}

			A principal ferramenta utilizada durante o desenvolvimento de código de aprendizado de máquina chama-se Jupyter Notebook \footnote{http://jupyter.org/}. Essa ferramenta é uma aplicação \emph{web} de distribuição gratuita, que permite a criação e compartilhamento de documentos com código que pode ser interpretado interativamente, conforme se vai programando, e que, junto dos trechos de código executado coloca suas saídas, bem como gráficos gerados pelo trecho, além de permitir ao usuário colocar explicações ou textos gerais em liguagem Markdown, em meio ao código, de forma a explicá-lo. É uma ferramenta altamente utilizada para aplicações de análise de dados atualmente.

		\subsection{Etapas para o desenvolvimento de aplicação de aprendizado de máquina}

			% https://www.ibm.com/developerworks/community/blogs/jfp/entry/What_Is_Machine_Learning?lang=en
			% https://machinelearningmastery.com/machine-learning-in-python-step-by-step/
			% https://medium.com/dunder-data/how-to-learn-pandas-108905ab4955
			% https://www.digitalocean.com/community/tutorials/
			% how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn  → fala sobre como funciona a divisao em pedaços do data set
			% TODO colocar referencia à seção direito

			O desenvolvimento de aplicações de aprendizado de máquina é caracterizado por algumas etapas.

			Inicialmente, é necessário explicitar qual o problema a ser resolvido. Na seção "Aprendizado de máquina no projeto Hedwig" foi exposto o problema aqui explorado.

			O próximo passo é a coleta de dados, para que os modelos possam ser treinados. Expusemos essa etapa no capítulo anterior.

			Em seguida, é necessário realizar algumas análises de dados e tratamentos dos mesmos, para que se possa sanitizá-los e deixá-los em formato propício ao uso pelos algoritmos. Também é necessário separar uma parcela dos dados para servir para treinamento dos modelos, e outra parcela para servir de dados de teste.

			Tendo isso pronto, pode-se então passar a uma etapa de treinamento de modelos. Para isso, é necessário fazer uma análise de quais algoritmos poderiam se encaixar bem para o problema em questão.

			A partir do treinamento dos modelos, e da separação de alguns dados para teste, é possível então avaliar quão bem os algoritmos estão performando para a previsão de resultados.

			O último passo costuma ser a elaboração do produto final: normalmente a integração sistema de aprendizado com outras aplicações ou então a elaboração de relatórios para que os modelos treinados para o problema sejam levados adiante.

			Nas próximas seções exploraremos o desenvolvimento desses últimos passos no projeto Hedwig.

		\subsection{Algoritmos}
			% É algoritmo supervisionado, de classificacao --> pegar referencias do ISLR

				Existem duas classificações gerais para algoritmos de aprendizado de máquina: os de aprendizado supervisionado e os de aprendizado não supervisionado. Os algoritmos de aprendizado supervisionado são caracterizados por tratarem de problemas nos quais se possui uma

					ISLR: Broadly speaking,
			supervised statistical learning involves building a statistical model for pre-
			dicting, or estimating, an output based on one or more inputs. Problems of
			this nature occur in fields as diverse as business, medicine, astrophysics, and
			public policy. With unsupervised statistical learning, there are inputs but
			no supervising output; nevertheless we can learn relationships and struc-
			ture from such data. To provide an illustration of some applications of
			statistical learning, we briefly discuss three real-world data sets that are
			considered in this book.

		\subsection{Tratamento de dados}
			% http://scott.fortmann-roe.com/docs/BiasVariance.html
			% Falar sobre tratamento dos dados: undersampling/oversampling (fato de que a maioria dos dados de ativação é falso)

			No problema em análise, os dados que possuímos são:

			\begin{itemize}
				\item \emph{Timestamp} com dia e hora
				\item Luminosidade
				\item Temperatura
				\item Umidade
				\item Presença
				\item Ativação do relé (para o relé 1 e para o relé 2)
				\item Tipo de ativação (via botão, app backup, controle remoto, ativação agendada)
				\item Status dos relés
			\end{itemize}

			O objetivo de nosso primeiro estudo então é o desenvolvimento de um modelo que aprenda a prever quando ocorrerá uma ativação do relé pelo usuário.

			A primeira coisa que é necessária de ser levada em consideração é que a ativação pode ter ocorrido em decorrência de um agendamento. Nesse caso, devemos desconsiderar essa ativação, já que não se trata de uma ativação do usuário e não nos ajuda a prever quando o usuário irá deseajar ativar o relé.

			Outra questão a ser levada em analisada é a presença de uma disparidade entre a quantidade de amostras de treino que estão em uma classificação, em relação à quantidade que está em outra. No caso em análise, existem muito mais dados nos quais não ocorreu ativação do relé pelo usuário (71) do que os que ocorreram (6851). Ou seja, aproximadamente 99\% dos dados estão em uma classificação, e apenas 1\% na outra. Esse problema é conhecido como \emph{Class Imbalance Problem}. Para resolvê-lo, há duas táticas principais: \emph{oversampling} e \emph{undersampling}. Essa disparidade é um problema devido ao fato de que os algoritmos classificadores têm como objetivo a maximização da sua taxa de acerto. Dessa forma, teria alta tendência a sempre classificar os dados como pertencentes à classe majoritária. Isso é um problema principalmente em casos onde as situações de interesse são exatamente as que menos ocorre, como é o caso do problema aqui em exploração.

			% loans.bad_loans.value_counts()

			As duas táticas procuram balancear a quantidade de amostras em cada uma das classes. Pela tática de \emph{undersampling} isso é feito retirando-se algumas amostras da classe majoritária. Pela tática de \emph{oversampling}, isso é feito adicionando-se amostras da classe minoritária. Também existe a tática híbrida, que combina as duas anteriores.

			% The disadvantage with undersampling is that it discards potentially useful data. The main disadvantage with oversampling, from our perspective, is that by making exact copies of existing examples, it makes overfitting likely.
			% https://beckernick.github.io/oversampling-modeling/

			% https://pdfs.semanticscholar.org/9908/404807bf6b63e05e5345f02bcb23cc739ebd.pdf

			% http://www.chioka.in/class-imbalance-problem/

% SMOTE technique

% https://github.com/scikit-learn-contrib/imbalanced-learn
% 			@article{JMLR:v18:16-365,
% author  = {Guillaume  Lema{{\^i}}tre and Fernando Nogueira and Christos K. Aridas},
% title   = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
% journal = {Journal of Machine Learning Research},
% year    = {2017},
% volume  = {18},
% number  = {17},
% pages   = {1-5},
% url     = {http://jmlr.org/papers/v18/16-365}
% }


		\subsection{Treinamento dos modelos}

		\subsection{Resultados obtidos}

		\subsection{Otimização dos modelos}

% citar que conforme fosse sendo usado o sistema iria aprendendo cada vez mais
